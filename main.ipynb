{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from flygym import Fly, Simulation, Camera, get_data_path\n",
    "from flygym.arena import FlatTerrain\n",
    "from flygym.preprogrammed import all_leg_dofs\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "#sys.path.append('C:/Users/laeti/Documents/laetitia/EPFL/Master/CoursMA2/Control_Behaviour/projet')\n",
    "from hybrid_turning_fly import HybridTurningFly\n",
    "from simulation_CPG import Simulation_CPG\n",
    "from flygym.examples.cpg_controller import CPGNetwork\n",
    "from IPython import display\n",
    "from flygym.vision import save_video_with_vision_insets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualTaxisFly(HybridTurningFly):\n",
    "    def __init__(self, obj_threshold=0.15, decision_interval=0.05, **kwargs):\n",
    "        super().__init__(**kwargs, enable_vision=True)\n",
    "        self.obj_threshold = obj_threshold\n",
    "        self.decision_interval = decision_interval\n",
    "        self.num_substeps = int(self.decision_interval / self.timestep)\n",
    "        self.visual_inputs_hist = []\n",
    "\n",
    "        self.coms = np.empty((self.retina.num_ommatidia_per_eye, 2))\n",
    "\n",
    "        for i in range(self.retina.num_ommatidia_per_eye):\n",
    "            mask = self.retina.ommatidia_id_map == i + 1\n",
    "            self.coms[i, :] = np.argwhere(mask).mean(axis=0)\n",
    "\n",
    "    def process_visual_observation(self, vision_input):\n",
    "        features = np.zeros((2, 3))\n",
    "\n",
    "        for i, ommatidia_readings in enumerate(vision_input):\n",
    "            is_obj = ommatidia_readings.max(axis=1) < self.obj_threshold\n",
    "            is_obj_coords = self.coms[is_obj]\n",
    "\n",
    "            if is_obj_coords.shape[0] > 0:\n",
    "                features[i, :2] = is_obj_coords.mean(axis=0)\n",
    "\n",
    "            features[i, 2] = is_obj_coords.shape[0]\n",
    "\n",
    "        features[:, 0] /= self.retina.nrows  # normalize y_center\n",
    "        features[:, 1] /= self.retina.ncols  # normalize x_center\n",
    "        features[:, 2] /= self.retina.num_ommatidia_per_eye  # normalize area\n",
    "        return features.ravel().astype(\"float32\")\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_ipsilateral_speed(deviation, is_found):\n",
    "        if not is_found:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return np.clip(1 - deviation * 3, 0.4, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingFly(Fly):\n",
    "    def __init__(self, init_pose=\"stretch\", actuated_joints=None, control=\"position\",\n",
    "                 initial_position=None, initial_orientation=None, **kwargs):\n",
    "        super().__init__(**kwargs, init_pose=init_pose, actuated_joints=actuated_joints, control=control,\n",
    "                         spawn_pos=initial_position, spawn_orientation=initial_orientation, enable_vision=True)\n",
    "        self.visual_inputs_hist = []\n",
    "\n",
    "    def simulate_step(self, sim: Simulation, yaw_angle: float, perform_movement: bool = False, side: str='L'):\n",
    "        if perform_movement:\n",
    "            action = {\"joints\": self.simulate_movement(sim, yaw_angle, side)}\n",
    "        else:\n",
    "            action = {\"joints\": self.obs[\"joints\"][0].copy()} \n",
    "        action[\"adhesion\"] = np.array([1,0,1,1,0,1]) #add adhesion \n",
    "        return action\n",
    "\n",
    "    def simulate_movement(self, sim: Simulation, yaw_angle: float, side: str):\n",
    "        joint_pos = self.obs[\"joints\"][0].copy()\n",
    "\n",
    "        if side == \"L\":\n",
    "            joint_pos[8:14] = 0 #straigten the leg\n",
    "            joint_pos[7], joint_pos[9] = 1.57, yaw_angle  # Setting specific yaw and pitch\n",
    "        else:\n",
    "            joint_pos[29:35] = 0 #straigten the leg\n",
    "            joint_pos[28], joint_pos[30] = 1.57, yaw_angle\n",
    "\n",
    "        return joint_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario(start_postion=0):\n",
    "    pos = (0,4.5,0)\n",
    "    orien_fwd = (0,0,np.pi/2)\n",
    "    orien_bcd =(0,0,-np.pi/2)\n",
    "\n",
    "    match start_postion:\n",
    "        case 0 : return pos, orien_fwd\n",
    "        case 1:\n",
    "            pos = (16,4.5,0)\n",
    "            return pos, orien_bcd\n",
    "        case 2:\n",
    "            pos = (16,-4.5,0)\n",
    "            return pos, orien_bcd\n",
    "        case 3 :\n",
    "            return (0,-4.5,0), orien_fwd\n",
    "        case TypeError:\n",
    "            print(\"wrong start_position, default values taken\")\n",
    "            return pos, orien_fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 1e-4\n",
    "scenario_fly1=0\n",
    "\n",
    "fly = Fly(\n",
    "    name=\"1\",\n",
    "    init_pose=\"stretch\",\n",
    "    actuated_joints=all_leg_dofs,\n",
    "    control=\"position\",\n",
    "    enable_adhesion=True,\n",
    "    draw_adhesion=False,\n",
    "    spawn_pos= scenario(scenario_fly1)[0],\n",
    "    spawn_orientation = scenario(scenario_fly1)[1]\n",
    ")\n",
    "\n",
    "#need to process visual informations\n",
    "# fly0 = VisualTaxisFly(\n",
    "#     name=\"0\", #static\n",
    "#     timestep=timestep,\n",
    "#     enable_adhesion=True,\n",
    "#     head_stabilization_model=\"thorax\",\n",
    "#     neck_kp=1000,\n",
    "#     spawn_pos=(8,0,0), #position\n",
    "#     spawn_orientation = (0,0,-np.pi/2)\n",
    "# )\n",
    "\n",
    "fly0 = MovingFly(\n",
    "\n",
    "    name=\"0\", #static\n",
    "    init_pose=\"stretch\",\n",
    "    actuated_joints=all_leg_dofs,\n",
    "    control=\"position\",\n",
    "    enable_adhesion=True,\n",
    "    head_stabilization_model=\"thorax\",\n",
    "    neck_kp=1000,\n",
    "    initial_position=(8,0,0), #position\n",
    "    initial_orientation = (0,0,-np.pi/2)\n",
    ")\n",
    "\n",
    "\n",
    "arena = FlatTerrain()\n",
    "\n",
    "birdeye_cam_zoom = arena.root_element.worldbody.add(\n",
    "    \"camera\",\n",
    "    name=\"birdeye_cam_zoom\",\n",
    "    mode=\"fixed\",\n",
    "    pos=(15, 0, 20),\n",
    "    euler=(0, 0, 0),\n",
    "    fovy=45,\n",
    ")\n",
    "\n",
    "birdeye_cam = arena.root_element.worldbody.add(\n",
    "    \"camera\",\n",
    "    name=\"birdeye_cam\",\n",
    "    mode=\"fixed\",\n",
    "    pos=(15, 0, 35),\n",
    "    euler=(0, 0, 0),\n",
    "    fovy=45,\n",
    ")\n",
    "\n",
    "cam = Camera(\n",
    "    fly=fly0,\n",
    "    camera_id=\"birdeye_cam\",\n",
    "    play_speed=0.5,\n",
    "    window_size=(800, 608),\n",
    ")\n",
    "\n",
    "sim = Simulation(\n",
    "    flies=[fly0, fly],\n",
    "    cameras=[cam],\n",
    "    arena=arena,\n",
    "    timestep=timestep,\n",
    ")\n",
    "\n",
    "simulation_cpg = Simulation_CPG(timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init\n",
    "run_time = 1\n",
    "obs, info = sim.reset(seed=0)\n",
    "\n",
    "for i in fly.model.find_all(\"geom\"):\n",
    "    sim.physics.named.model.geom_rgba[f\"1/{i.name}\"] = (0, 0, 0, 1)\n",
    "\n",
    "\n",
    "second_cam_frames = []\n",
    "\n",
    "#fly0_action = {\"joints\": np.array([joints_angles[dof] for dof in fly0.actuated_joints])}\n",
    "fly0_action = {\"joints\": np.zeros(len(fly0.actuated_joints)), \"adhesion\": np.array([1,0,1,1,0,1])}\n",
    "\n",
    "x = None\n",
    "alpha = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugo/miniconda3/envs/flygymv1/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), groups=2)\n",
       "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), groups=2)\n",
       "  (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), groups=2)\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): LazyLinear(in_features=0, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the vision model\n",
    "\n",
    "from utils import crop_hex_to_rect\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define your layers here\n",
    "        self.conv1 = nn.Conv2d(2, 8, 3, groups=2)  # Convolutional layer\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.conv2 = nn.Conv2d(8, 8, 3, groups=2)  # Convolutional layer\n",
    "        self.bn2 = nn.BatchNorm2d(8)\n",
    "        self.conv3 = nn.Conv2d(8, 8, 3, groups=2)  # Convolutional layer\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)  # Max pooling layer\n",
    "        self.fc1 = nn.LazyLinear(16)  # Lazy linear layer\n",
    "        self.fc2 = nn.Linear(16, 16)  # Linear layer\n",
    "        self.fc3 = nn.Linear(16, 2)   # Linear layer for output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = self.bn2(x)  # Apply pooling after the second convolution\n",
    "        x = F.tanh(self.conv3(x))\n",
    "        x = self.pool3(x)  # Apply pooling after the third convolution\n",
    "        x = x.flatten(1)   # Flatten the output to feed into linear layers\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Create an instance of the model\n",
    "model = Model()\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load('./best_model/best_model_vision.pth'))\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2508/10000 [00:17<01:01, 121.93it/s]/var/folders/9b/zp5p8_495653n52_yn4hbq9h0000gn/T/ipykernel_2072/1779317081.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  joint_pos[7], joint_pos[9] = 1.57, yaw_angle  # Setting specific yaw and pitch\n",
      " 26%|██▌       | 2595/10000 [00:18<00:46, 159.63it/s]/var/folders/9b/zp5p8_495653n52_yn4hbq9h0000gn/T/ipykernel_2072/1779317081.py:24: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  joint_pos[28], joint_pos[30] = 1.57, yaw_angle\n",
      " 26%|██▋       | 2628/10000 [00:18<00:54, 134.08it/s]WARNING:absl:Nan, Inf or huge value in QACC at DOF 39. The simulation is unstable. Time = 0.2639.\n",
      " 26%|██▋       | 2639/10000 [00:18<00:51, 142.92it/s]\n"
     ]
    },
    {
     "ename": "PhysicsError",
     "evalue": "Physics state is invalid. Warning(s) raised: mjWARN_BADQACC",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPhysicsError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m trange(\u001b[39mint\u001b[39m(run_time \u001b[39m/\u001b[39m sim\u001b[39m.\u001b[39mtimestep)):\n\u001b[1;32m      2\u001b[0m     fly1_action \u001b[39m=\u001b[39m simulation_cpg\u001b[39m.\u001b[39mupdate(fly\u001b[39m.\u001b[39mactuated_joints)\n\u001b[0;32m----> 3\u001b[0m     obs, _,_ ,_ , info \u001b[39m=\u001b[39m sim\u001b[39m.\u001b[39;49mstep({\n\u001b[1;32m      4\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m0\u001b[39;49m\u001b[39m\"\u001b[39;49m : fly0_action,\n\u001b[1;32m      5\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m\"\u001b[39;49m : fly1_action,\n\u001b[1;32m      6\u001b[0m     })\n\u001b[1;32m      8\u001b[0m     obs0, info0 \u001b[39m=\u001b[39m obs[\u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m], info[\u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m     fly0\u001b[39m.\u001b[39mobs \u001b[39m=\u001b[39m obs0\n",
      "File \u001b[0;32m~/flygymv1/flygym/simulation.py:215\u001b[0m, in \u001b[0;36mSimulation.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mfor\u001b[39;00m fly \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflies:\n\u001b[1;32m    213\u001b[0m     fly\u001b[39m.\u001b[39mpre_step(action[fly\u001b[39m.\u001b[39mname], \u001b[39mself\u001b[39m)\n\u001b[0;32m--> 215\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mphysics\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurr_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimestep\n\u001b[1;32m    218\u001b[0m obs, reward, terminated, truncated, info \u001b[39m=\u001b[39m {}, {}, {}, {}, {}\n",
      "File \u001b[0;32m~/miniconda3/envs/flygymv1/lib/python3.11/site-packages/dm_control/mujoco/engine.py:172\u001b[0m, in \u001b[0;36mPhysics.step\u001b[0;34m(self, nstep)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, nstep: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Advances the physics state by `nstep`s.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39m  The actuation can be updated by calling the `set_control` function first.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m   \u001b[39mwith\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_invalid_state():\n\u001b[1;32m    173\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlegacy_step:\n\u001b[1;32m    174\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_with_up_to_date_position_velocity(nstep)\n",
      "File \u001b[0;32m~/miniconda3/envs/flygymv1/lib/python3.11/contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen)\n\u001b[1;32m    145\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/flygymv1/lib/python3.11/site-packages/dm_control/mujoco/engine.py:344\u001b[0m, in \u001b[0;36mPhysics.check_invalid_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m message \u001b[39m=\u001b[39m _INVALID_PHYSICS_STATE\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    342\u001b[0m     warning_names\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(warning_names))\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warnings_cause_exception:\n\u001b[0;32m--> 344\u001b[0m   \u001b[39mraise\u001b[39;00m _control\u001b[39m.\u001b[39mPhysicsError(message)\n\u001b[1;32m    345\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m   logging\u001b[39m.\u001b[39mwarn(message)\n",
      "\u001b[0;31mPhysicsError\u001b[0m: Physics state is invalid. Warning(s) raised: mjWARN_BADQACC"
     ]
    }
   ],
   "source": [
    "for _ in trange(int(run_time / sim.timestep)):\n",
    "    fly1_action = simulation_cpg.update(fly.actuated_joints)\n",
    "    obs, _,_ ,_ , info = sim.step({\n",
    "        \"0\" : fly0_action,\n",
    "        \"1\" : fly1_action,\n",
    "    })\n",
    "\n",
    "    obs0, info0 = obs[\"0\"], info[\"0\"]\n",
    "    fly0.obs = obs0\n",
    "    render_res = sim.render()[0]\n",
    "\n",
    "    if render_res is not None:\n",
    "        fly0.visual_inputs_hist.append(obs0[\"vision\"].copy())\n",
    "        second_cam = sim.physics.bind(birdeye_cam_zoom)\n",
    "\n",
    "        x_new = sim._get_center_of_mass()[0]\n",
    "\n",
    "        if x is None:\n",
    "            x = x_new\n",
    "\n",
    "        x = (1 - alpha) * x + alpha * x_new\n",
    "\n",
    "        second_cam.pos[0] = x\n",
    "        second_img = sim.physics.render(\n",
    "            width=700, height=560, camera_id=\"birdeye_cam_zoom\"\n",
    "        )\n",
    "        second_img = cv2.putText(\n",
    "            np.ascontiguousarray(second_img),\n",
    "            f\"{sim.cameras[0].play_speed}x\",\n",
    "            org=(20, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "            fontScale=0.8,\n",
    "            color=(0, 0, 0),\n",
    "            lineType=cv2.LINE_AA,\n",
    "            thickness=1,\n",
    "        )\n",
    "        second_cam_frames.append(second_img)\n",
    "\n",
    "    #visual_features = fly0.process_visual_observation(obs0[\"vision\"])\n",
    "        \n",
    "\n",
    "    #process the image :\n",
    "        \n",
    "    imgs = crop_hex_to_rect(obs0[\"vision\"])\n",
    "    imgs = np.expand_dims(imgs, axis=0) #transform into a 4d vector to match the training data\n",
    "\n",
    "    with torch.no_grad(): #gradient doesn't flow back in the model\n",
    "        coords_lr_pred = model(torch.tensor(imgs)).numpy()\n",
    "\n",
    "    #prediction of the other fly's position\n",
    "    theta_pred = np.angle(coords_lr_pred @ (1, -1j) * np.exp(1j * np.pi / 4))\n",
    "    distances = np.linalg.norm(coords_lr_pred, axis=1)\n",
    "\n",
    "    #print(theta_pred,distances)\n",
    "\n",
    "    #defining side and offset -> front to the side \n",
    "    if theta_pred > 0:\n",
    "        side='R'\n",
    "        real_angle = theta_pred + np.deg2rad(90) #offset on the leg actuator\n",
    "    else:\n",
    "        side='L'\n",
    "        real_angle = theta_pred - np.deg2rad(90) #offset on the leg actuator\n",
    "\n",
    "    #getting the action based on the observer \n",
    "    if distances<=2: #to change when it's done\n",
    "        fly0_action = fly0.simulate_step(sim, yaw_angle=real_angle, perform_movement=True, side=side)\n",
    "    else:\n",
    "        fly0_action = fly0.simulate_step(sim, yaw_angle=real_angle, perform_movement=False, side=side)\n",
    "    \n",
    "cam.save_video(\"./outputs/cpg_controller_with_adhesion.mp4\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Video(\"./outputs/cpg_controller_with_adhesion.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdeye_cam_frames = cam._frames\n",
    "cam._frames = second_cam_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.fly = fly0\n",
    "\n",
    "save_video_with_vision_insets(\n",
    "    sim,\n",
    "    cam,\n",
    "    \"outputs/fly_following_with_retina_images.mp4\",\n",
    "    fly0.visual_inputs_hist,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Video(\"./outputs/fly_following_with_retina_images.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flygym-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
