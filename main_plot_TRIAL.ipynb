{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from flygym import Fly, Simulation, Camera, get_data_path\n",
    "from flygym.arena import FlatTerrain\n",
    "from flygym.preprogrammed import all_leg_dofs\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "#sys.path.append('C:/Users/laeti/Documents/laetitia/EPFL/Master/CoursMA2/Control_Behaviour/projet')\n",
    "from hybrid_turning_fly import HybridTurningFly\n",
    "from simulation_CPG import Simulation_CPG\n",
    "from flygym.examples.cpg_controller import CPGNetwork\n",
    "from IPython import display\n",
    "from flygym.vision import save_video_with_vision_insets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\laeti\\documents\\laetitia\\epfl\\master\\coursma2\\control_behaviour\\projet\\flygym-v1\\flygym\\core.py:331: UserWarning: Deprecation warning: The `NeuroMechFly` class has been restructured into `Simulation`, `Fly`, and `Camera`.`NeuroMechFly` will be removed in future versions.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from flygym import Parameters, NeuroMechFly\n",
    "nmf = NeuroMechFly(Parameters(enable_adhesion=True, draw_adhesion=True))\n",
    "from flygym.examples.common import PreprogrammedSteps\n",
    "\n",
    "#Filtering initialization :\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "preprogrammed_steps = PreprogrammedSteps()\n",
    "swing_periods = preprogrammed_steps.swing_period\n",
    "legs = preprogrammed_steps.legs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualTaxisFly(HybridTurningFly):\n",
    "    def __init__(self, obj_threshold=0.15, decision_interval=0.05, **kwargs):\n",
    "        super().__init__(**kwargs, enable_vision=True)\n",
    "        self.obj_threshold = obj_threshold\n",
    "        self.decision_interval = decision_interval\n",
    "        self.num_substeps = int(self.decision_interval / self.timestep)\n",
    "        self.visual_inputs_hist = []\n",
    "\n",
    "        self.coms = np.empty((self.retina.num_ommatidia_per_eye, 2))\n",
    "\n",
    "        for i in range(self.retina.num_ommatidia_per_eye):\n",
    "            mask = self.retina.ommatidia_id_map == i + 1\n",
    "            self.coms[i, :] = np.argwhere(mask).mean(axis=0)\n",
    "\n",
    "    def process_visual_observation(self, vision_input):\n",
    "        features = np.zeros((2, 3))\n",
    "\n",
    "        for i, ommatidia_readings in enumerate(vision_input):\n",
    "            is_obj = ommatidia_readings.max(axis=1) < self.obj_threshold\n",
    "            is_obj_coords = self.coms[is_obj]\n",
    "\n",
    "            if is_obj_coords.shape[0] > 0:\n",
    "                features[i, :2] = is_obj_coords.mean(axis=0)\n",
    "\n",
    "            features[i, 2] = is_obj_coords.shape[0]\n",
    "\n",
    "        features[:, 0] /= self.retina.nrows  # normalize y_center\n",
    "        features[:, 1] /= self.retina.ncols  # normalize x_center\n",
    "        features[:, 2] /= self.retina.num_ommatidia_per_eye  # normalize area\n",
    "        return features.ravel().astype(\"float32\")\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_ipsilateral_speed(deviation, is_found):\n",
    "        if not is_found:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return np.clip(1 - deviation * 3, 0.4, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingFly(Fly):\n",
    "    def __init__(self, init_pose=\"stretch\", actuated_joints=None, control=\"position\",\n",
    "                 initial_position=None, initial_orientation=None, **kwargs):\n",
    "        super().__init__(**kwargs, init_pose=init_pose, actuated_joints=actuated_joints, control=control,\n",
    "                         spawn_pos=initial_position, spawn_orientation=initial_orientation, enable_vision=True)\n",
    "        self.visual_inputs_hist = []\n",
    "        self.standing=[] #joints angles to stand\n",
    "        self.strech=[] #linespace to strech the elg\n",
    "        self.middle_stance_ids=[] #je sais pas a quoi ca sert\n",
    "        self.mid_leg_end_effector=[] #init des end effector\n",
    "        self.joint_record=[] #init des end effector\n",
    "\n",
    "    def simulate_step(self, sim: Simulation, roll_angle: float, yaw_angle: float, side: str='L'):\n",
    "        action = {\"joints\": self.simulate_movement(sim, roll_angle, yaw_angle, side)}\n",
    "        action[\"adhesion\"] = np.array([1,0,1,1,0,1]) #add adhesion \n",
    "        return action\n",
    "\n",
    "    def simulate_movement(self, sim: Simulation, roll_angle: float, yaw_angle: float, side: str, increment: float = 0.00015,):\n",
    "        joint_pos = self.standing.copy()\n",
    "\n",
    "        joint_angles = preprogrammed_steps.get_joint_angles(\"LM\" if side == \"L\" else \"RM\", 0)\n",
    "\n",
    "        if side == \"L\":\n",
    "            joint_pos[7:14] = joint_angles + self.strech\n",
    "            joint_pos[9], joint_pos[7] = roll_angle, yaw_angle  # Setting specific yaw and pitch\n",
    "        else:\n",
    "            joint_pos[28:35] = joint_angles + self.strech\n",
    "            joint_pos[30], joint_pos[28] = roll_angle, yaw_angle\n",
    "\n",
    "        #print(joint_pos[28:35])\n",
    "        #self.record_mov(sim, side, joint_pos)\n",
    "        return joint_pos\n",
    "\n",
    "    def record_mov(self, sim: Simulation, side: str, joint_pos):\n",
    "        observation = self.get_observation(sim)\n",
    "        end_effector = observation[\"end_effectors\"]\n",
    "        if side=='L': mid_leg_end_effector.append([end_effector[1,:]])\n",
    "        else : mid_leg_end_effector.append([end_effector[3,:]])\n",
    "        \n",
    "        self.mid_leg_end_effector.append()\n",
    "        self.joint_record.append=(joint_pos)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario(start_postion=0):\n",
    "    pos = (0,4.5,0)\n",
    "    orien_fwd = (0,0,np.pi/2)\n",
    "    orien_bcd =(0,0,-np.pi/2)\n",
    "\n",
    "    match start_postion:\n",
    "        case 0 : return pos, orien_fwd\n",
    "        case 1:\n",
    "            pos = (16,4.5,0)\n",
    "            return pos, orien_bcd\n",
    "        case 2:\n",
    "            pos = (16,-4.5,0)\n",
    "            return pos, orien_bcd\n",
    "        case 3 :\n",
    "            return (0,-5,0), orien_fwd\n",
    "        case TypeError:\n",
    "            print(\"wrong start_position, default values taken\")\n",
    "            return pos, orien_fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 1e-4\n",
    "scenario_fly1=0\n",
    "\n",
    "fly = Fly(\n",
    "    name=\"1\",\n",
    "    init_pose=\"stretch\",\n",
    "    actuated_joints=all_leg_dofs,\n",
    "    control=\"position\",\n",
    "    enable_adhesion=True,\n",
    "    draw_adhesion=False,\n",
    "    spawn_pos= scenario(scenario_fly1)[0],\n",
    "    spawn_orientation = scenario(scenario_fly1)[1]\n",
    ")\n",
    "\n",
    "#need to process visual informations\n",
    "# fly0 = VisualTaxisFly(\n",
    "#     name=\"0\", #static\n",
    "#     timestep=timestep,\n",
    "#     enable_adhesion=True,\n",
    "#     head_stabilization_model=\"thorax\",\n",
    "#     neck_kp=1000,\n",
    "#     spawn_pos=(8,0,0), #position\n",
    "#     spawn_orientation = (0,0,-np.pi/2)\n",
    "# )\n",
    "\n",
    "fly0 = MovingFly(\n",
    "\n",
    "    name=\"0\", #static\n",
    "    init_pose=\"stretch\",\n",
    "    actuated_joints=all_leg_dofs,\n",
    "    control=\"position\",\n",
    "    enable_adhesion=True,\n",
    "    head_stabilization_model=\"thorax\",\n",
    "    neck_kp=1000,\n",
    "    initial_position=(8,0,0), #position\n",
    "    initial_orientation = (0,0,-np.pi/2)\n",
    ")\n",
    "\n",
    "\n",
    "arena = FlatTerrain()\n",
    "\n",
    "birdeye_cam_zoom = arena.root_element.worldbody.add(\n",
    "    \"camera\",\n",
    "    name=\"birdeye_cam_zoom\",\n",
    "    mode=\"fixed\",\n",
    "    pos=(15, 0, 20),\n",
    "    euler=(0, 0, 0),\n",
    "    fovy=45,\n",
    ")\n",
    "\n",
    "birdeye_cam = arena.root_element.worldbody.add(\n",
    "    \"camera\",\n",
    "    name=\"birdeye_cam\",\n",
    "    mode=\"fixed\",\n",
    "    pos=(15, 0, 35),\n",
    "    euler=(0, 0, 0),\n",
    "    fovy=45,\n",
    ")\n",
    "\n",
    "cam = Camera(\n",
    "    fly=fly0,\n",
    "    camera_id=\"birdeye_cam\",\n",
    "    play_speed=0.5,\n",
    "    window_size=(800, 608),\n",
    ")\n",
    "\n",
    "# sim = Simulation(\n",
    "#     flies=[fly0, fly],\n",
    "#     cameras=[cam],\n",
    "#     arena=arena,\n",
    "#     timestep=timestep,\n",
    "# )\n",
    "\n",
    "cam1 = Camera(fly=fly0, play_speed=0.2, draw_contacts=False, camera_follows_fly_orientation=True)\n",
    "\n",
    "sim = Simulation(\n",
    "    flies=[fly0, fly],\n",
    "    cameras=[cam1, cam],\n",
    "    arena=arena,\n",
    "    timestep=timestep,\n",
    ")\n",
    "\n",
    "simulation_cpg = Simulation_CPG(timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\laeti\\anaconda3\\envs\\flygym-v1\\Lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), groups=2)\n",
       "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), groups=2)\n",
       "  (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), groups=2)\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): LazyLinear(in_features=0, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################## Vision Model definition ###############################\n",
    "#to see the training -> vision.ipynb\n",
    "\n",
    "from utils import crop_hex_to_rect\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define your layers here\n",
    "        self.conv1 = nn.Conv2d(2, 8, 3, groups=2)  # Convolutional layer\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.conv2 = nn.Conv2d(8, 8, 3, groups=2)  # Convolutional layer\n",
    "        self.bn2 = nn.BatchNorm2d(8)\n",
    "        self.conv3 = nn.Conv2d(8, 8, 3, groups=2)  # Convolutional layer\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)  # Max pooling layer\n",
    "        self.fc1 = nn.LazyLinear(16)  # Lazy linear layer\n",
    "        self.fc2 = nn.Linear(16, 16)  # Linear layer\n",
    "        self.fc3 = nn.Linear(16, 2)   # Linear layer for output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = self.bn2(x)  # Apply pooling after the second convolution\n",
    "        x = F.tanh(self.conv3(x))\n",
    "        x = self.pool3(x)  # Apply pooling after the third convolution\n",
    "        x = x.flatten(1)   # Flatten the output to feed into linear layers\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Create an instance of the model\n",
    "model = Model()\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load('./best_model/best_model_vision.pth'))\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Initialization ###############################\n",
    "\n",
    "run_time = 1\n",
    "obs, info = sim.reset(seed=0)\n",
    "\n",
    "for i in fly.model.find_all(\"geom\"):\n",
    "    sim.physics.named.model.geom_rgba[f\"1/{i.name}\"] = (0, 0, 0, 1)\n",
    "\n",
    "second_cam_frames = []\n",
    "x = None\n",
    "alpha = 1e-1\n",
    "\n",
    "\n",
    "#usefull constant\n",
    "target_num_steps=1000 #0.3/0.001 enginner joint angles\n",
    "\n",
    "middle_stance_ids = np.linspace(swing_periods[\"RM\"][1], 2 * np.pi, target_num_steps)\n",
    "\n",
    "\n",
    "\n",
    "roll_finished = False\n",
    "movement_roll=False\n",
    "i_roll=0\n",
    "\n",
    "########################## Filtering ###############################\n",
    "n = 50  # Number of observations for moving average\n",
    "theta_pred_history = deque(maxlen=n)\n",
    "distances_history = deque(maxlen=n)\n",
    "\n",
    "\n",
    "########################## Standing behaviour ###############################\n",
    "standing_action = []\n",
    "for leg in legs:\n",
    "    if leg.endswith(\"M\"):\n",
    "        standing_action.extend(\n",
    "            preprogrammed_steps.get_joint_angles(leg, swing_periods[leg][1])\n",
    "        )\n",
    "    else:\n",
    "        standing_action.extend(preprogrammed_steps.get_joint_angles(leg, 0.0))\n",
    "\n",
    "fly0_action = {\"joints\": standing_action, \"adhesion\": np.array([1,0,1,1,0,1])}\n",
    "fly0.standing= standing_action\n",
    "real_angle=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1591/5000 [00:56<01:44, 32.70it/s]"
     ]
    }
   ],
   "source": [
    "yam_history = []\n",
    "distances_sma_hist = []\n",
    "theta_pred_sma_hist=[]\n",
    "run_time=0.5\n",
    "\n",
    "distance_cond = False\n",
    "\n",
    "for _ in trange(int(run_time / sim.timestep)):\n",
    "    fly1_action = simulation_cpg.update(fly.actuated_joints)\n",
    "    obs, _,_ ,_ , info = sim.step({\n",
    "        \"0\" : fly0_action,\n",
    "        \"1\" : fly1_action,\n",
    "    })\n",
    "\n",
    "    obs0, info0 = obs[\"0\"], info[\"0\"]\n",
    "    fly0.obs = obs0\n",
    "    render_res = sim.render()[0]\n",
    "\n",
    "    if render_res is not None:\n",
    "        fly0.visual_inputs_hist.append(obs0[\"vision\"].copy())\n",
    "        second_cam = sim.physics.bind(birdeye_cam_zoom)\n",
    "\n",
    "        x_new = sim._get_center_of_mass()[0]\n",
    "\n",
    "        if x is None:\n",
    "            x = x_new\n",
    "\n",
    "        x = (1 - alpha) * x + alpha * x_new\n",
    "\n",
    "        second_cam.pos[0] = x\n",
    "        second_img = sim.physics.render(\n",
    "            width=700, height=560, camera_id=\"birdeye_cam_zoom\"\n",
    "        )\n",
    "        second_img = cv2.putText(\n",
    "            np.ascontiguousarray(second_img),\n",
    "            f\"{sim.cameras[0].play_speed}x\",\n",
    "            org=(20, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "            fontScale=0.8,\n",
    "            color=(0, 0, 0),\n",
    "            lineType=cv2.LINE_AA,\n",
    "            thickness=1,\n",
    "        )\n",
    "        second_cam_frames.append(second_img)\n",
    "        \n",
    "\n",
    "    ########################## NN Vision based on week 4 ###############################\n",
    "        \n",
    "    imgs = crop_hex_to_rect(obs0[\"vision\"]) #transform the image into a rectangle by croping\n",
    "    imgs = np.expand_dims(imgs, axis=0) #transform into a 4d vector to match the training data\n",
    "\n",
    "    with torch.no_grad(): #gradient doesn't flow back in the model\n",
    "        coords_lr_pred = model(torch.tensor(imgs)).numpy()\n",
    "\n",
    "    #prediction of the other fly's position\n",
    "    theta_pred = np.angle(coords_lr_pred @ (1, -1j) * np.exp(1j * np.pi / 4))\n",
    "    distances = np.linalg.norm(coords_lr_pred, axis=1)\n",
    "    ########################## Filtering ####################################\n",
    "    #Moving average\n",
    "    theta_pred_history.append(theta_pred)\n",
    "    distances_history.append(distances)\n",
    "\n",
    "    theta_pred_sma = np.mean(theta_pred_history)\n",
    "    distances_sma = np.mean(distances_history)\n",
    "\n",
    "    distances_sma_hist.append(distances_sma)\n",
    "    theta_pred_sma_hist.append(theta_pred_sma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ########################## Workspace transcription ###############################\n",
    "    #a verifier mais pas sur du tout\n",
    "    previous_angle = real_angle\n",
    "    if theta_pred_sma < 0:\n",
    "        side='R'\n",
    "        real_angle = -(theta_pred_sma + np.deg2rad(90)) #offset on the leg actuator\n",
    "    else:\n",
    "        side='L'\n",
    "        #real_angle = -(theta_pred_sma + np.deg2rad(90)) #offset on the leg actuator\n",
    "        real_angle= - theta_pred_sma + np.deg2rad(90)\n",
    "\n",
    "\n",
    "    ########################## Movement computation ###############################\n",
    "\n",
    "\n",
    "    if distances_sma<=8 or distance_cond :\n",
    "        distance_cond = True\n",
    "        if movement_roll== False: #find roll to give to the fly\n",
    "            L_midleg_start = preprogrammed_steps.get_joint_angles(\"LM\", 0.0)\n",
    "            L_midleg_stretch = np.linspace(np.zeros(len(L_midleg_start)), -L_midleg_start, target_num_steps)\n",
    "\n",
    "            R_midleg_start = preprogrammed_steps.get_joint_angles(\"RM\", 0.0)\n",
    "            R_midleg_stretch = np.linspace( np.zeros(len(R_midleg_start)), -R_midleg_start, target_num_steps)\n",
    "\n",
    "            if side=='L':\n",
    "                roll_lin= np.linspace(obs0[\"joints\"][0][9], 1.5, target_num_steps)\n",
    "            else : \n",
    "                roll_lin= np.linspace(obs0[\"joints\"][0][30], -1.5, target_num_steps)\n",
    "            movement_roll=True\n",
    "            previous_angle = real_angle #init\n",
    "            start_id=i\n",
    "        \n",
    "\n",
    "        if roll_finished:\n",
    "            if side=='L':\n",
    "                roll=1.5\n",
    "                fly0.strech=-L_midleg_start\n",
    "            else: \n",
    "                roll=-1.5\n",
    "                fly0.strech=-R_midleg_start\n",
    "        else:\n",
    "            roll = roll_lin[i_roll]   #once finished, stay at 1.5\n",
    "            if side=='L':\n",
    "                fly0.strech=L_midleg_stretch[i_roll]\n",
    "            else: \n",
    "                fly0.strech=R_midleg_stretch[i_roll]\n",
    "\n",
    "\n",
    "\n",
    "        if abs(previous_angle-real_angle)<10: use_angle = real_angle\n",
    "        else : use_angle = previous_angle\n",
    "\n",
    "        if i_roll==0: #if iterations is 0 modulo target_num_steps -> compute the new order to smooth out the movement\n",
    "            if side=='L':\n",
    "                joint_value = obs0[\"joints\"][0][7]\n",
    "                #use_angle-= np.deg2rad(90)\n",
    "                yaw_lin = np.linspace(joint_value, use_angle, target_num_steps)            \n",
    "\n",
    "            else : \n",
    "                joint_value = obs0[\"joints\"][0][28]\n",
    "                yaw_lin = - np.linspace(joint_value, use_angle, target_num_steps)\n",
    "            \n",
    "        yam_history.append(obs0[\"joints\"][0][7])\n",
    "\n",
    "        fly0.middle_stance_ids=middle_stance_ids[i_roll]\n",
    "        #print(roll)\n",
    "        fly0_action = fly0.simulate_step(sim, roll_angle=roll, yaw_angle=yaw_lin[i_roll], side=side) #action to follow the intruder \n",
    "\n",
    "        #update i roll and check if the movement is finished\n",
    "        i_roll+=1\n",
    "        if i_roll % target_num_steps == 0 : \n",
    "            roll_finished=True\n",
    "            i_roll=0\n",
    "\n",
    "    #compute the case where the fly is not in the range anymore -> linespace roll a l'envers et linespace vers 0 pour yaw\n",
    "\n",
    "    ########################## If no detection ###############################\n",
    "    else:\n",
    "        fly0_action = {\"joints\": standing_action, \"adhesion\": np.array([1,0,1,1,0,1])} #the fly stay still\n",
    "\n",
    "    previous_distances_sma = distances_sma\n",
    "\n",
    "    \n",
    "cam.save_video(\"./outputs/cpg_controller_with_adhesionX.mp4\", 0)\n",
    "cam1.save_video(\"./outputs/kinematic_B_replay1X.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/cpg_controller_with_adhesionX.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam.save_video(\"./outputs/cpg_controller_with_adhesionX.mp4\", 0)\n",
    "\n",
    "display.Video(\"./outputs/cpg_controller_with_adhesionX.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdeye_cam_frames = cam._frames\n",
    "cam._frames = second_cam_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (700, 715) to (704, 720) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "sim.fly = fly0\n",
    "\n",
    "save_video_with_vision_insets(\n",
    "    sim,\n",
    "    cam,\n",
    "    \"outputs/fly_following_with_retina_imagesX.mp4\",\n",
    "    fly0.visual_inputs_hist,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/fly_following_with_retina_imagesX.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.Video(\"./outputs/fly_following_with_retina_imagesX.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/kinematic_B_replay1X.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.Video(\"./outputs/kinematic_B_replay1X.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (5000,) and (50,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m time_points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m(run_time\u001b[38;5;241m/\u001b[39mtimestep), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m distances_list \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m distances_history]\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#plt.plot(time_points, theta_pred_history)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\laeti\\anaconda3\\envs\\flygym-v1\\Lib\\site-packages\\matplotlib\\pyplot.py:3590\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3582\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3584\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3588\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3594\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3595\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3596\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\laeti\\anaconda3\\envs\\flygym-v1\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1724\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1724\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1725\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1726\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\laeti\\anaconda3\\envs\\flygym-v1\\Lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\laeti\\anaconda3\\envs\\flygym-v1\\Lib\\site-packages\\matplotlib\\axes\\_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5000,) and (50,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_points = np.arange(0, int(run_time/timestep), 1)\n",
    "distances_list = [item[0] for item in distances_history]\n",
    "plt.plot(time_points, distances_list)\n",
    "#plt.plot(time_points, theta_pred_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([array([8.5757265], dtype=float32),\n",
       "       array([8.5757265], dtype=float32),\n",
       "       array([8.5757265], dtype=float32),\n",
       "       array([8.5757265], dtype=float32),\n",
       "       array([8.5757265], dtype=float32),\n",
       "       array([8.5757265], dtype=float32),\n",
       "       array([8.5757265], dtype=float32),\n",
       "       array([8.5757265], dtype=float32),\n",
       "       array([8.5757265], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([8.436917], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([7.724943], dtype=float32),\n",
       "       array([6.7895355], dtype=float32)],\n",
       "      maxlen=50)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_pred_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_eff_x =  mid_leg_end_effector[:, 0, 0]\n",
    "end_eff_y = mid_leg_end_effector[:, 0, 1]\n",
    "end_eff_z = mid_leg_end_effector[:, 0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(end_eff_x, end_eff_y, label='R End Effector')\n",
    "plt.plot(end_eff_x, end_eff_z, label='R End Effector')\n",
    "plt.plot(end_eff_y, end_eff_z, label='R End Effector')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flygym-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
